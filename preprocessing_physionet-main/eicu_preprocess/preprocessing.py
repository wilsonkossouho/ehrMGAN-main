"""
preprocessing_eicu_complete.py

Script complet de preprocessing : eICU-CRD Demo â†’ Format EHR-M-GAN
GÃ©nÃ¨re les 4 fichiers requis en une seule exÃ©cution :
  1. vital_sign_24hrs.pkl
  2. med_interv_24hrs.pkl
  3. statics.pkl
  4. norm_stats.npz

Usage:
    python preprocessing_eicu_complete.py
"""

import pandas as pd
import numpy as np
import pickle
import os
from pathlib import Path
from tqdm import tqdm
import warnings

warnings.filterwarnings('ignore')

# ============================================================================
# CONFIGURATION
# ============================================================================

# Chemins
EICU_PATH = Path('data/real/eicu/raw/eicu-collaborative-research-database-demo-2.0.1')
OUTPUT_PATH = Path('data/real/eicu')
OUTPUT_PATH.mkdir(parents=True, exist_ok=True)

# ParamÃ¨tres
WINDOW_HOURS = 24  # FenÃªtre de 24 heures
MIN_ICU_STAY_HOURS = 24  # SÃ©jour minimum 24h
MIN_AGE = 15
MAX_AGE = 89
MIN_MEASUREMENTS = 12  # Au moins 12 mesures par patient

print("=" * 80)
print(" " * 20 + "ðŸ”„ PREPROCESSING eICU â†’ EHR-M-GAN")
print("=" * 80)
print(f"\nâš™ï¸  Configuration:")
print(f"  â€¢ Chemin eICU : {EICU_PATH}")
print(f"  â€¢ FenÃªtre temporelle : {WINDOW_HOURS} heures")
print(f"  â€¢ SÃ©jour minimum : {MIN_ICU_STAY_HOURS}h")
print(f"  â€¢ Ã‚ge : {MIN_AGE}-{MAX_AGE} ans")
print("=" * 80)

# ============================================================================
# Ã‰TAPE 1 : CHARGER ET FILTRER LES PATIENTS
# ============================================================================

print("\n" + "=" * 80)
print("ðŸ“‹ Ã‰TAPE 1/6 : Chargement et filtrage des patients")
print("=" * 80)

# Charger la table patients
print("\n  ðŸ“‚ Chargement de patient.csv.gz...")
patients = pd.read_csv(EICU_PATH / 'patient.csv.gz', compression='gzip')
print(f"     âœ… {len(patients):,} admissions chargÃ©es")

initial_count = len(patients)

# Filtrer par Ã¢ge
print("\n  ðŸ” Filtrage par Ã¢ge...")
patients = patients[patients['age'] != ''].copy()
patients['age_numeric'] = patients['age'].replace('> 89', '90').astype(float)
patients = patients[(patients['age_numeric'] >= MIN_AGE) & (patients['age_numeric'] <= MAX_AGE)]
print(f"     âœ… {initial_count:,} â†’ {len(patients):,} patients")

# Un sÃ©jour par patient (premier sÃ©jour seulement)
print("\n  ðŸ” Filtrage : premier sÃ©jour ICU uniquement...")
initial_count = len(patients)
patients = patients.sort_values(['patienthealthsystemstayid', 'unitvisitnumber'])
patients = patients.groupby('patienthealthsystemstayid').first().reset_index()
print(f"     âœ… {initial_count:,} â†’ {len(patients):,} patients")

# Filtrer par durÃ©e de sÃ©jour
print(f"\n  ðŸ” Filtrage : sÃ©jour >= {MIN_ICU_STAY_HOURS}h...")
initial_count = len(patients)
min_offset = MIN_ICU_STAY_HOURS * 60  # Convertir en minutes
patients = patients[patients['unitdischargeoffset'] >= min_offset]
print(f"     âœ… {initial_count:,} â†’ {len(patients):,} patients")

# CrÃ©er le label de mortalitÃ©
patients['label'] = (patients['unitdischargestatus'] == 'Expired').astype(int)

print(f"\n  âœ… Cohorte finale : {len(patients):,} patients")
print(f"     â€¢ Taux de mortalitÃ© ICU : {patients['label'].mean() * 100:.1f}%")

# ============================================================================
# Ã‰TAPE 2 : EXTRAIRE LES SIGNAUX VITAUX (DONNÃ‰ES CONTINUES)
# ============================================================================

print("\n" + "=" * 80)
print("ðŸ“Š Ã‰TAPE 2/6 : Extraction des signaux vitaux (continues)")
print("=" * 80)

# Features vitales Ã  extraire
VITAL_FEATURES = [
    'heartrate',  # FrÃ©quence cardiaque
    'respiration',  # FrÃ©quence respiratoire
    'spo2',  # Saturation en oxygÃ¨ne
    'temperature',  # TempÃ©rature
    'systemicsystolic',  # Pression systolique
    'systemicdiastolic',  # Pression diastolique
    'systemicmean'  # Pression moyenne
]

print(f"\n  ðŸ“‚ Chargement de vitalPeriodic.csv.gz...")
vitals = pd.read_csv(EICU_PATH / 'vitalPeriodic.csv.gz', compression='gzip')
print(f"     âœ… {len(vitals):,} mesures chargÃ©es")

# Filtrer sur la cohorte
valid_ids = set(patients['patientunitstayid'])
vitals = vitals[vitals['patientunitstayid'].isin(valid_ids)]

print(f"\n  ðŸ”„ Extraction des fenÃªtres 24h pour {len(valid_ids):,} patients...")

continuous_data_list = []
valid_patient_ids = []
failed_patients = 0

for _, patient in tqdm(patients.iterrows(), total=len(patients), desc="  Traitement"):
    patient_id = patient['patientunitstayid']
    discharge_offset = patient['unitdischargeoffset']

    # FenÃªtre : [discharge - 24h, discharge]
    start_offset = discharge_offset - (WINDOW_HOURS * 60)
    end_offset = discharge_offset

    # Extraire les vitaux dans cette fenÃªtre
    patient_vitals = vitals[
        (vitals['patientunitstayid'] == patient_id) &
        (vitals['observationoffset'] >= start_offset) &
        (vitals['observationoffset'] <= end_offset)
        ].copy()

    if len(patient_vitals) < MIN_MEASUREMENTS:
        failed_patients += 1
        continue

    # Convertir offset en heures relatives (0-24)
    patient_vitals['hour'] = (patient_vitals['observationoffset'] - start_offset) / 60
    patient_vitals['hour'] = patient_vitals['hour'].clip(0, WINDOW_HOURS)
    patient_vitals['hour_bin'] = patient_vitals['hour'].astype(int).clip(0, WINDOW_HOURS - 1)

    # SÃ©lectionner les features
    vital_cols = [col for col in VITAL_FEATURES if col in patient_vitals.columns]

    # AgrÃ©gation horaire (moyenne)
    vitals_hourly = patient_vitals.groupby('hour_bin')[vital_cols].mean()

    # Reindex pour avoir exactement 24 heures
    vitals_hourly = vitals_hourly.reindex(range(WINDOW_HOURS))

    # Imputation : forward fill â†’ backward fill â†’ mean
    vitals_hourly = vitals_hourly.fillna(method='ffill').fillna(method='bfill')
    vitals_hourly = vitals_hourly.fillna(vitals_hourly.mean())

    # Si toujours des NaN, skip
    if vitals_hourly.isnull().any().any():
        failed_patients += 1
        continue

    continuous_data_list.append(vitals_hourly.values)
    valid_patient_ids.append(patient_id)

continuous_data = np.array(continuous_data_list)

print(f"\n  âœ… Extraction terminÃ©e :")
print(f"     â€¢ Patients traitÃ©s avec succÃ¨s : {len(valid_patient_ids):,}")
print(f"     â€¢ Patients Ã©chouÃ©s (donnÃ©es insuffisantes) : {failed_patients}")
print(f"     â€¢ Shape finale : {continuous_data.shape}")
print(f"     â€¢ Features : {len(VITAL_FEATURES)} ({', '.join(VITAL_FEATURES[:3])}...)")

# ============================================================================
# Ã‰TAPE 3 : EXTRAIRE LES INTERVENTIONS MÃ‰DICALES (DONNÃ‰ES DISCRÃˆTES)
# ============================================================================

print("\n" + "=" * 80)
print("ðŸ’Š Ã‰TAPE 3/6 : Extraction des interventions mÃ©dicales (discrÃ¨tes)")
print("=" * 80)

# Features d'interventions
DISCRETE_FEATURES = [
    'mechanical_ventilation',
    'vasopressor',
    'dialysis'
]

print(f"\n  ðŸ“‚ Chargement de treatment.csv.gz et infusiondrug.csv.gz...")
treatment = pd.read_csv(EICU_PATH / 'treatment.csv.gz', compression='gzip')
infusion = pd.read_csv(EICU_PATH / 'infusiondrug.csv.gz', compression='gzip')
print(f"     âœ… {len(treatment):,} traitements + {len(infusion):,} infusions")

# Filtrer sur la cohorte valide
treatment = treatment[treatment['patientunitstayid'].isin(valid_patient_ids)]
infusion = infusion[infusion['patientunitstayid'].isin(valid_patient_ids)]

print(f"\n  ðŸ”„ Extraction des interventions 24h pour {len(valid_patient_ids):,} patients...")

discrete_data_list = []
vasopressor_drugs = ['norepinephrine', 'epinephrine', 'dopamine',
                     'vasopressin', 'phenylephrine', 'dobutamine', 'milrinone']

for patient_id in tqdm(valid_patient_ids, desc="  Traitement"):

    patient_info = patients[patients['patientunitstayid'] == patient_id].iloc[0]
    discharge_offset = patient_info['unitdischargeoffset']
    start_offset = discharge_offset - (WINDOW_HOURS * 60)
    end_offset = discharge_offset

    # Initialiser matrice [24, 3]
    interventions = np.zeros((WINDOW_HOURS, len(DISCRETE_FEATURES)))

    # 1. VENTILATION MÃ‰CANIQUE
    vent_keywords = ['ventilation', 'intubation', 'mechanical vent', 'intubated']
    vent = treatment[
        (treatment['patientunitstayid'] == patient_id) &
        (treatment['treatmentstring'].str.contains('|'.join(vent_keywords),
                                                   case=False, na=False)) &
        (treatment['treatmentoffset'] >= start_offset) &
        (treatment['treatmentoffset'] <= end_offset)
        ]

    for _, row in vent.iterrows():
        hour_bin = int((row['treatmentoffset'] - start_offset) / 60)
        hour_bin = max(0, min(hour_bin, WINDOW_HOURS - 1))
        interventions[hour_bin, 0] = 1

    # Forward fill : si ventilÃ© Ã  t, reste ventilÃ© jusqu'Ã  changement
    for i in range(1, WINDOW_HOURS):
        if interventions[i, 0] == 0 and interventions[i - 1, 0] == 1:
            interventions[i, 0] = 1

    # 2. VASOPRESSEURS
    vaso = infusion[
        (infusion['patientunitstayid'] == patient_id) &
        (infusion['drugname'].str.lower().isin(vasopressor_drugs)) &
        (infusion['infusionoffset'] >= start_offset) &
        (infusion['infusionoffset'] <= end_offset)
        ]

    for _, row in vaso.iterrows():
        hour_bin = int((row['infusionoffset'] - start_offset) / 60)
        hour_bin = max(0, min(hour_bin, WINDOW_HOURS - 1))
        interventions[hour_bin, 1] = 1

    # 3. DIALYSE
    dialysis_keywords = ['dialysis', 'CRRT', 'hemodialysis', 'hemofiltration']
    dial = treatment[
        (treatment['patientunitstayid'] == patient_id) &
        (treatment['treatmentstring'].str.contains('|'.join(dialysis_keywords),
                                                   case=False, na=False)) &
        (treatment['treatmentoffset'] >= start_offset) &
        (treatment['treatmentoffset'] <= end_offset)
        ]

    for _, row in dial.iterrows():
        hour_bin = int((row['treatmentoffset'] - start_offset) / 60)
        hour_bin = max(0, min(hour_bin, WINDOW_HOURS - 1))
        interventions[hour_bin, 2] = 1

    discrete_data_list.append(interventions)

discrete_data = np.array(discrete_data_list)

print(f"\n  âœ… Extraction terminÃ©e :")
print(f"     â€¢ Shape finale : {discrete_data.shape}")
print(f"     â€¢ Features : {DISCRETE_FEATURES}")
print(f"     â€¢ Taux d'activation :")
for i, feature in enumerate(DISCRETE_FEATURES):
    rate = (discrete_data[:, :, i].sum() / discrete_data[:, :, i].size) * 100
    print(f"       - {feature}: {rate:.1f}%")

# ============================================================================
# Ã‰TAPE 4 : CRÃ‰ER LES LABELS STATIQUES
# ============================================================================

print("\n" + "=" * 80)
print("ðŸ·ï¸  Ã‰TAPE 4/6 : CrÃ©ation des labels statiques")
print("=" * 80)

# Filtrer patients sur la cohorte valide
patients_final = patients[patients['patientunitstayid'].isin(valid_patient_ids)]
patients_final = patients_final.set_index('patientunitstayid').loc[valid_patient_ids].reset_index()

# Extraire les labels
statics_label = patients_final[['label']].values

print(f"\n  âœ… Labels crÃ©Ã©s :")
print(f"     â€¢ Shape : {statics_label.shape}")
print(f"     â€¢ MortalitÃ© ICU : {statics_label.sum()}/{len(statics_label)} ({statics_label.mean() * 100:.1f}%)")

# ============================================================================
# Ã‰TAPE 5 : NORMALISATION MIN-MAX
# ============================================================================

print("\n" + "=" * 80)
print("ðŸ“ Ã‰TAPE 5/6 : Normalisation des donnÃ©es continues")
print("=" * 80)

print("\n  ðŸ”„ Application de la normalisation min-max...")

# Calculer min/max sur toutes les dimensions (patients + temps)
min_val = continuous_data.min(axis=(0, 1), keepdims=True)
max_val = continuous_data.max(axis=(0, 1), keepdims=True)

# Ã‰viter division par zÃ©ro
range_val = max_val - min_val
range_val[range_val == 0] = 1.0

# Normaliser
continuous_data_normalized = (continuous_data - min_val) / range_val

print(f"\n  âœ… Normalisation terminÃ©e :")
print(f"     â€¢ Range : [0, 1]")
print(f"     â€¢ Min par feature : {min_val.squeeze()}")
print(f"     â€¢ Max par feature : {max_val.squeeze()}")

# ============================================================================
# Ã‰TAPE 6 : SAUVEGARDER LES FICHIERS
# ============================================================================

print("\n" + "=" * 80)
print("ðŸ’¾ Ã‰TAPE 6/6 : Sauvegarde des fichiers finaux")
print("=" * 80)

print(f"\n  ðŸ“ RÃ©pertoire de sortie : {OUTPUT_PATH.absolute()}\n")

# 1. vital_sign_24hrs.pkl
filepath = OUTPUT_PATH / 'vital_sign_24hrs.pkl'
with open(filepath, 'wb') as f:
    # pickle.dump(continuous_data_normalized, f, pickle.HIGHEST_PROTOCOL)
    pickle.dump(continuous_data_normalized, f, 4)
print(f"  âœ… {filepath.name}")
print(f"     Shape: {continuous_data_normalized.shape}, dtype: {continuous_data_normalized.dtype}")

# 2. med_interv_24hrs.pkl
filepath = OUTPUT_PATH / 'med_interv_24hrs.pkl'
with open(filepath, 'wb') as f:
    # pickle.dump(discrete_data, f, pickle.HIGHEST_PROTOCOL)
    pickle.dump(discrete_data, f, 4)
print(f"  âœ… {filepath.name}")
print(f"     Shape: {discrete_data.shape}, dtype: {discrete_data.dtype}")

# 3. statics.pkl
filepath = OUTPUT_PATH / 'statics.pkl'
with open(filepath, 'wb') as f:
    # pickle.dump(statics_label, f, pickle.HIGHEST_PROTOCOL)
    pickle.dump(statics_label, f, 4)
print(f"  âœ… {filepath.name}")
print(f"     Shape: {statics_label.shape}, dtype: {statics_label.dtype}")

# 4. norm_stats.npz
filepath = OUTPUT_PATH / 'norm_stats.npz'
np.savez(filepath,
         min_val=min_val.squeeze(),
         max_val=max_val.squeeze())
print(f"  âœ… {filepath.name}")
print(f"     Min/Max stats pour dÃ©normalisation")

# ============================================================================
# RÃ‰SUMÃ‰ FINAL
# ============================================================================

print("\n" + "=" * 80)
print(" " * 25 + "âœ… PREPROCESSING TERMINÃ‰ !")
print("=" * 80)

print(f"\nðŸ“Š RÃ‰SUMÃ‰ :")
print(f"  â€¢ Patients traitÃ©s : {len(valid_patient_ids):,}")
print(f"  â€¢ DonnÃ©es continues : {continuous_data_normalized.shape}")
print(f"    â†’ Features : {VITAL_FEATURES}")
print(f"  â€¢ DonnÃ©es discrÃ¨tes : {discrete_data.shape}")
print(f"    â†’ Features : {DISCRETE_FEATURES}")
print(f"  â€¢ Labels : {statics_label.shape}")
print(f"  â€¢ Taux de mortalitÃ© : {statics_label.mean() * 100:.1f}%")

print(f"\nðŸ“ FICHIERS CRÃ‰Ã‰S :")
print(f"  1. vital_sign_24hrs.pkl")
print(f"  2. med_interv_24hrs.pkl")
print(f"  3. statics.pkl")
print(f"  4. norm_stats.npz")

print(f"\nðŸš€ PROCHAINE Ã‰TAPE :")
print(f"  Lancez l'entraÃ®nement EHR-M-GAN avec :")
print(f"  cd ../../ehrMGAN-main")
print(f"  python main_train.py --dataset eicu")

print("\n" + "=" * 80)